{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules/packages\n",
    "import os\n",
    "import numpy as np\n",
    "from shutil import copy\n",
    "\n",
    "# Import third-party modules/packages\n",
    "# import utils\n",
    "from utils import File, Command, NiiFile, LogFile, TmpDir, DependencyError\n",
    "from typing import List, Optional, Union, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scripts_dir = os.path.realpath(__file__)\n",
    "scripts_dir = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRtrixError(Exception):\n",
    "    pass\n",
    "\n",
    "class FSLError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReconMRtrix (object):\n",
    "    '''Class that contains the associated wrapper functions for performing\n",
    "    tractography using MRtrix v3.x.\n",
    "    \n",
    "    Attributes:\n",
    "        *\n",
    "    \n",
    "    To-do:\n",
    "        * Write general purpose mif to nifti and (nifti to mif) conversion function(s)\n",
    "    '''\n",
    "    \n",
    "    nii_file: NiiFile = \"\"\n",
    "    bval: File = \"\"\n",
    "    bvec: File = \"\"\n",
    "    json_file: File = \"\"\n",
    "    log: LogFile = \"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 nii_file: str,\n",
    "                 bval: str,\n",
    "                 bvec: str,\n",
    "                 json_file: Optional[str] = None,\n",
    "                 log: Optional[str] = None\n",
    "                ) -> None:\n",
    "        '''Init doc string for ReconMRtrix class.\n",
    "        \n",
    "        Usage example:\n",
    "            >>> dwi_obj = ReconMRtrix(\"file.nii\",\n",
    "            >>>                       \"file.bval\",\n",
    "            >>>                       \"file.bvec\",\n",
    "            >>>                       \"file.json\",\n",
    "            >>>                       \"file.log\")\n",
    "            >>> dwi_obj.file\n",
    "            \"file.nii\"\n",
    "        \n",
    "        Args:\n",
    "            nii_file: Input file path to DWI NIFTI file.\n",
    "            bval: Input file path to corresponding bval file.\n",
    "            bvec: Input file path to corresponding bvec file.\n",
    "            json_file: Input file path to corresponding JSON (sidecar) file.\n",
    "            log: Log filename for output log file (, need not exist at runtime).\n",
    "        '''\n",
    "        self.nii_file: str = nii_file\n",
    "        self.bval: str = bval\n",
    "        self.bvec: str = bvec\n",
    "        \n",
    "        self.nii_file = NiiFile(self.nii_file)\n",
    "        self.bval = File(self.bval)\n",
    "        self.bvec = File(self.bvec)\n",
    "        \n",
    "        if json_file:\n",
    "            self.json_file: str = json_file\n",
    "            self.json_file = File(self.json_file)\n",
    "        else:\n",
    "            self.json_file = \"\"\n",
    "            self.json_file = File(self.json_file)\n",
    "            \n",
    "        if log:\n",
    "            self.log: str = log\n",
    "            self.log = LogFile(self.log)\n",
    "        else:\n",
    "            self.log: str = \"\"\n",
    "            self.log = LogFile(self.log)\n",
    "        \n",
    "    class Mif(File):\n",
    "        '''Creates MIF files for use with MRtrix executables. Inherits \n",
    "        methods and properties from the File class.\n",
    "        \n",
    "        Attributes:\n",
    "            * \n",
    "        '''\n",
    "        \n",
    "        def __init__(self,\n",
    "                     file: File,\n",
    "                     gzip: bool = False\n",
    "                    ) -> None:\n",
    "            '''Init doc string for Mif class. Inherits methods and properties\n",
    "            from the File class. The MIF file can also be gzipped if desired.\n",
    "            \n",
    "            Usage example:\n",
    "                >>> dwi_obj = ReconMRtrix(\"file.nii\",\n",
    "                >>>                       \"file.bval\",\n",
    "                >>>                       \"file.bvec\",\n",
    "                >>>                       \"file.json\",\n",
    "                >>>                       \"file.log\")\n",
    "                >>> dwi_obj.Mif(dwi_obj.file)\n",
    "                >>> dwi_obj.Mif.file\n",
    "                >>> \"file.mif\"\n",
    "                >>>\n",
    "                >>> # To gzip the MIF file\n",
    "                >>> dwi_obj.Mif(dwi_obj.file,gzip=True)\n",
    "            \n",
    "            Args:\n",
    "                file: Input filename of MIF file (need not exist).\n",
    "                gzip: Gzips output MIF file\n",
    "            '''\n",
    "            self.file = file\n",
    "            \n",
    "            if '.gz' in self.file:\n",
    "                if gzip:\n",
    "                    self.ext: str = self.file[-(7):]\n",
    "                    self.file = self.file[:-(7)] + \".mif.gz\"\n",
    "                else:\n",
    "                    self.ext: str = self.file[-(7):]\n",
    "                    self.file = self.file[:-(7)] + \".mif\"\n",
    "            else:\n",
    "                if gzip:\n",
    "                    self.ext: str = self.file[-(4):]\n",
    "                    self.file = self.file[:-(4)] + \".mif.gz\"\n",
    "                else:\n",
    "                    self.ext: str = self.file[-(4):]\n",
    "                    self.file = self.file[:-(4)] + \".mif\"\n",
    "            File.__init__(self,self.file,self.ext)\n",
    "    \n",
    "    def nifti_to_mif(self,\n",
    "                     force: bool = False,\n",
    "                     gzip: bool = False\n",
    "                    ) -> Mif:\n",
    "        '''Converts DWI NIFTI file and its associated files to MIF files.\n",
    "        \n",
    "        Usage example:\n",
    "            >>> dwi_obj = ReconMRtrix(\"file.nii\",\n",
    "            >>>                       \"file.bval\",\n",
    "            >>>                       \"file.bvec\",\n",
    "            >>>                       \"file.json\",\n",
    "            >>>                       \"file.log\")\n",
    "            >>> dwi_obj.nifti_to_mif()\n",
    "            >>> Mif\n",
    "        \n",
    "        Args:\n",
    "            force: Force overwrite of existing MIF file.\n",
    "            gzip: Gzip output MIF file.\n",
    "        \n",
    "        Returns:\n",
    "            mif_file: Mif file object.\n",
    "        '''\n",
    "        mif_file: str = self.nii_file.abs_path()\n",
    "        mif_file: Mif = self.Mif(mif_file,gzip=gzip)\n",
    "        \n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        if force:\n",
    "            mr_convert.cmd_list.append(\"-force\")\n",
    "        if self.json_file:\n",
    "            mr_convert.cmd_list.append(\"-json_import\")\n",
    "            mr_convert.cmd_list.append(self.json_file.file)\n",
    "        mr_convert.cmd_list.append(\"-fslgrad\")\n",
    "        mr_convert.cmd_list.append(f\"{self.bvec.file}\")\n",
    "        mr_convert.cmd_list.append(f\"{self.bval.file}\")\n",
    "        mr_convert.cmd_list.append(f\"{self.nii_file.file}\")\n",
    "        mr_convert.cmd_list.append(f\"{mif_file.file}\")\n",
    "        \n",
    "        mr_convert.run(self.log)\n",
    "        return mif_file\n",
    "    \n",
    "    def estimate_response(self,\n",
    "                          mif: Mif,\n",
    "                          method: str = \"dhollander\",\n",
    "                          force: bool = False,\n",
    "                          gzip: bool = False\n",
    "                         ) -> Tuple[File,File,File]:\n",
    "        '''doc-string\n",
    "        Todo:\n",
    "            * function returns should be File objects, not strs\n",
    "        '''\n",
    "        [path, filename, ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        wm_res: str = os.path.join(path,filename + \"_response_wm.txt\")\n",
    "        gm_res: str = os.path.join(path,filename + \"_response_gm.txt\")\n",
    "        csf_res: str = os.path.join(path,filename + \"_response_csf.txt\")\n",
    "            \n",
    "        wm_res: File = File(wm_res)\n",
    "        gm_res: File = File(gm_res)\n",
    "        csf_res: File = File(csf_res)\n",
    "        \n",
    "        dwi_response = Command(\"dwi2response\")\n",
    "        if force:\n",
    "            dwi_response.cmd_list.append(\"-force\")\n",
    "        dwi_response.cmd_list.append(method)\n",
    "        dwi_response.cmd_list.append(mif.file)\n",
    "        dwi_response.cmd_list.append(wm_res.file)\n",
    "        dwi_response.cmd_list.append(gm_res.file)\n",
    "        dwi_response.cmd_list.append(csf_res.file)\n",
    "        \n",
    "        dwi_response.run(self.log)\n",
    "        \n",
    "        return wm_res, gm_res, csf_res\n",
    "    \n",
    "    def mr_upsample(self,\n",
    "                    mif: Mif,\n",
    "                    vox: float,\n",
    "                    gzip: bool = False\n",
    "                   ) -> Mif:\n",
    "        '''doc-string'''\n",
    "        # [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        # [_path, _filename, ext] = mif.file_parts() # Keep original file extension\n",
    "        \n",
    "        if \".mif\" in mif.file:\n",
    "            if \".gz\" in mif.file:\n",
    "                gzip = True\n",
    "                _ext = \".mif.gz\"\n",
    "            else:\n",
    "                _ext = \".mif\"\n",
    "        elif \".nii\" in mif.file:\n",
    "            if \".gz\" in mif.file:\n",
    "                gzip = True\n",
    "                _ext = \".nii.gz\"\n",
    "            else:\n",
    "                _ext = \".nii\"\n",
    "            \n",
    "        # if gzip:\n",
    "        #     ext = \".mif.gz\"\n",
    "        # else:\n",
    "        #     ext = \".mif\"\n",
    "        ext = \".mif\"\n",
    "        \n",
    "        \n",
    "        [path, filename, _ext] = mif.file_parts(ext=_ext) # Keep original file extension\n",
    "        \n",
    "        filename = filename + f\"_upsampled_vox_{vox}mm\"\n",
    "        upsampled_mif = os.path.join(path,filename + ext)\n",
    "        upsampled_mif: Mif = self.Mif(upsampled_mif,gzip=gzip)\n",
    "        \n",
    "        try:\n",
    "            upsample = Command(\"mrresize\")\n",
    "            upsample.check_dependency()\n",
    "            upsample.cmd_list.append(mif.file)\n",
    "            upsample.cmd_list.append(\"-vox\")\n",
    "            upsample.cmd_list.append(f\"{vox}\")\n",
    "            upsample.cmd_list.append(upsampled_mif.file)\n",
    "            upsample.run(self.log)\n",
    "            return upsampled_mif\n",
    "        except DependencyError:\n",
    "            upsample = Command(\"mrgrid\")\n",
    "            upsample.check_dependency()\n",
    "            upsample.cmd_list.append(mif.file)\n",
    "            upsample.cmd_list.append(\"regrid\")\n",
    "            upsample.cmd_list.append(upsampled_mif.file)\n",
    "            upsample.cmd_list.append(\"-voxel\")\n",
    "            upsample.cmd_list.append(f\"{vox}\")\n",
    "            upsample.run(self.log)\n",
    "            return upsampled_mif\n",
    "    \n",
    "    def create_mask(self,\n",
    "                    mif: Mif,\n",
    "                    frac_int: float = 0.5,\n",
    "                    gzip: bool = False,\n",
    "                    cleanup: bool = True\n",
    "                   ) -> Tuple[Mif,Mif,Mif]:\n",
    "        '''doc-string'''\n",
    "        [path, _filename, _ext] = self.nii_file.file_parts()\n",
    "        [_path, filename, ext] = mif.file_parts() # Keep original file extension\n",
    "        \n",
    "        if \".gz\" in mif.file:\n",
    "            gzip = True\n",
    "        \n",
    "        file_head = filename + \"_head\"\n",
    "        filename = filename + \"_brain\"\n",
    "        file_mask = filename + \"_mask\"\n",
    "        \n",
    "        brain_mif = os.path.join(path,filename + ext)\n",
    "        mask_mif = os.path.join(path,file_mask + ext)\n",
    "        head_mif = os.path.join(path,file_head + ext)\n",
    "        \n",
    "        brain_mif = self.Mif(brain_mif,gzip=gzip)\n",
    "        mask_mif: Mif = self.Mif(mask_mif,gzip=gzip)\n",
    "        head_mif: Mif = self.Mif(head_mif,gzip=gzip)\n",
    "            \n",
    "        # Create temporary directory\n",
    "        work_dir: TmpDir = TmpDir(tmp_dir=path,use_cwd=False)\n",
    "        work_dir.mk_tmp_dir()\n",
    "        \n",
    "        tmp_b0s: TmpFile = work_dir.TmpFile(tmp_file=\"tmp_B0s\" + _ext,\n",
    "                                            tmp_dir=work_dir.tmp_dir)\n",
    "        \n",
    "        tmp_b0: TmpFile = work_dir.TmpFile(tmp_file=\"tmp_B0\" + _ext,\n",
    "                                           tmp_dir=work_dir.tmp_dir)\n",
    "        \n",
    "        tmp_mask: TmpFile = work_dir.TmpFile(tmp_file=tmp_b0.rm_ext(ext=_ext) + \n",
    "                                             \"_brain\" + _ext,\n",
    "                                             tmp_dir=work_dir.tmp_dir)\n",
    "        \n",
    "        # Extract B0s\n",
    "        extract_b0s = Command(\"dwiextract\")\n",
    "        extract_b0s.cmd_list.append(\"-bzero\")\n",
    "        extract_b0s.cmd_list.append(mif.file)\n",
    "        extract_b0s.cmd_list.append(tmp_b0s.file)\n",
    "        extract_b0s.run(self.log)\n",
    "        \n",
    "        # Merge B0s, by obtaining mean of images\n",
    "        merge_b0s = Command(\"fslmaths\")\n",
    "        merge_b0s.cmd_list.append(tmp_b0s.file)\n",
    "        merge_b0s.cmd_list.append(\"-Tmean\")\n",
    "        merge_b0s.cmd_list.append(tmp_b0.file)\n",
    "        merge_b0s.run(self.log)\n",
    "        \n",
    "        # Create brain mask\n",
    "        bet = Command(\"bet\")\n",
    "        bet.cmd_list.append(tmp_b0.file)\n",
    "        bet.cmd_list.append(tmp_mask.file)\n",
    "        bet.cmd_list.append(\"-R\")\n",
    "        bet.cmd_list.append(\"-m\")\n",
    "        bet.cmd_list.append(\"-f\")\n",
    "        bet.cmd_list.append(f\"{frac_int}\")\n",
    "        bet.run(self.log)\n",
    "        \n",
    "        # Convert NIFTI to MIF\n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(tmp_mask.rm_ext(ext=_ext) + \"_mask.nii.gz\")\n",
    "        mr_convert.cmd_list.append(mask_mif.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(tmp_mask.file)\n",
    "        mr_convert.cmd_list.append(brain_mif.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(tmp_b0.file)\n",
    "        mr_convert.cmd_list.append(head_mif.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        # Clean-up\n",
    "        if cleanup:\n",
    "            work_dir.rm_tmp_dir(rm_parent=False)\n",
    "        \n",
    "        return mask_mif,brain_mif,head_mif\n",
    "        \n",
    "    def ss3t_csd(self,\n",
    "                 mif: Mif,\n",
    "                 mask: Mif,\n",
    "                 wm_res: File,\n",
    "                 gm_res: File,\n",
    "                 csf_res: File,\n",
    "                 gzip: bool = False) -> Tuple[Mif,Mif,Mif]:\n",
    "        '''doc-string'''\n",
    "        [path, _filename, _ext] = self.nii_file.file_parts()\n",
    "        [_path, filename, ext] = mif.file_parts() # Keep original file extension\n",
    "        \n",
    "        if \".gz\" in mif.file:\n",
    "            gzip = True\n",
    "        \n",
    "        wm_fod = filename + \"_wm_fod\"\n",
    "        gm_tis = filename + \"_gm_tis\"\n",
    "        csf_tis = filename + \"_csf_tis\"\n",
    "        \n",
    "        wm_fod: str = os.path.join(path,wm_fod + ext)\n",
    "        gm_tis: str = os.path.join(path,gm_tis + ext)\n",
    "        csf_tis: str = os.path.join(path,csf_tis + ext)\n",
    "        \n",
    "        wm_fod: Mif = self.Mif(wm_fod,gzip=gzip)\n",
    "        gm_tis: Mif = self.Mif(gm_tis,gzip=gzip)\n",
    "        csf_tis: Mif = self.Mif(csf_tis,gzip=gzip)\n",
    "        \n",
    "        # Compute WM FOD\n",
    "        ss3t = Command(\"ss3t_csd_beta1\")\n",
    "        ss3t.cmd_list.append(mif.file)\n",
    "        ss3t.cmd_list.append(wm_res.file)\n",
    "        ss3t.cmd_list.append(wm_fod.file)\n",
    "        ss3t.cmd_list.append(gm_res.file)\n",
    "        ss3t.cmd_list.append(gm_tis.file)\n",
    "        ss3t.cmd_list.append(csf_res.file)\n",
    "        ss3t.cmd_list.append(csf_tis.file)\n",
    "        ss3t.cmd_list.append(\"-mask\")\n",
    "        ss3t.cmd_list.append(mask.file)\n",
    "        ss3t.run(self.log)\n",
    "        return wm_fod, gm_tis, csf_tis\n",
    "    \n",
    "    def bias_field_correction(self,\n",
    "                              wm_fod: Mif,\n",
    "                              gm_tis: Mif,\n",
    "                              csf_tis: Mif,\n",
    "                              mask: Mif, \n",
    "                              gzip: bool = False\n",
    "                             ) -> Tuple[Mif,Mif,Mif]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        if \".gz\" in wm_fod.file:\n",
    "            gzip = True\n",
    "            ext = \".mif.gz\"\n",
    "        else:\n",
    "            ext = \".mif\"\n",
    "        \n",
    "        wm_fod_norm = filename + \"_wm_fod_norm\"\n",
    "        gm_tis_norm = filename + \"_gm_tis_norm\"\n",
    "        csf_tis_norm = filename + \"_csf_tis_norm\"\n",
    "        \n",
    "        wm_fod_norm: str = os.path.join(path,wm_fod_norm + ext)\n",
    "        gm_tis_norm: str = os.path.join(path,gm_tis_norm + ext)\n",
    "        csf_tis_norm: str = os.path.join(path,csf_tis_norm + ext)\n",
    "        \n",
    "        wm_fod_norm: Mif = self.Mif(wm_fod_norm,gzip=gzip)\n",
    "        gm_tis_norm: Mif = self.Mif(gm_tis_norm,gzip=gzip)\n",
    "        csf_tis_norm: Mif = self.Mif(csf_tis_norm,gzip=gzip)\n",
    "            \n",
    "        # Perform joint bias field correction\n",
    "        bias_correct = Command(\"mtnormalise\")\n",
    "        bias_correct.cmd_list.append(wm_fod.file)\n",
    "        bias_correct.cmd_list.append(wm_fod_norm.file)\n",
    "        bias_correct.cmd_list.append(gm_tis.file)\n",
    "        bias_correct.cmd_list.append(gm_tis_norm.file)\n",
    "        bias_correct.cmd_list.append(csf_tis.file)\n",
    "        bias_correct.cmd_list.append(csf_tis_norm.file)\n",
    "        bias_correct.cmd_list.append(\"-mask\")\n",
    "        bias_correct.cmd_list.append(mask.file)\n",
    "        bias_correct.run(self.log)\n",
    "        return wm_fod_norm, gm_tis_norm, csf_tis_norm\n",
    "    \n",
    "    def compute_dec_map(self,\n",
    "                        wm_fod: Mif,\n",
    "                        gm_tis: Mif,\n",
    "                        csf_tis: Mif,\n",
    "                        mask: Mif,\n",
    "                        gzip: bool = False) -> Tuple[Mif,Mif]:\n",
    "        '''doc-string\n",
    "        Todo:\n",
    "            * write shell script to produce vf maps\n",
    "        '''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        if \".gz\" in wm_fod.file:\n",
    "            gzip = True\n",
    "            ext = \".mif.gz\"\n",
    "        else:\n",
    "            ext = \".mif\"\n",
    "        \n",
    "        # Create output filenames\n",
    "        dec = os.path.join(path,filename + \"_dec\" + ext)\n",
    "        dec: Mif = self.Mif(dec,gzip=gzip)\n",
    "        \n",
    "        vf = os.path.join(path,filename + \"_vf\" + ext)\n",
    "        vf: Mif = self.Mif(vf,gzip=gzip)\n",
    "            \n",
    "        # Compute DEC map\n",
    "        fod2dec = Command(\"fod2dec\")\n",
    "        fod2dec.cmd_list.append(wm_fod.file)\n",
    "        fod2dec.cmd_list.append(dec.file)\n",
    "        fod2dec.cmd_list.append(\"-mask\")\n",
    "        fod2dec.cmd_list.append(mask.file)\n",
    "        fod2dec.run(self.log)\n",
    "        \n",
    "        # Compute RGB tissue (signal contribution) maps\n",
    "        vf_calc = os.path.join(scripts_dir,\"dwi_extra.sh\")\n",
    "        rgb = Command(vf_calc)\n",
    "        rgb.cmd_list.append(\"--wm-fod\")\n",
    "        rgb.cmd_list.append(wm_fod.file)\n",
    "        rgb.cmd_list.append(\"--gm\")\n",
    "        rgb.cmd_list.append(gm_tis.file)\n",
    "        rgb.cmd_list.append(\"--csf\")\n",
    "        rgb.cmd_list.append(csf_tis.file)\n",
    "        rgb.cmd_list.append(\"--out-vf\")\n",
    "        rgb.cmd_list.append(vf.file)\n",
    "        rgb.run(self.log)\n",
    "        \n",
    "        return dec, vf\n",
    "    \n",
    "    def mr_tck_global(self,\n",
    "                      wm_fod: Mif,\n",
    "                      mask: Mif,\n",
    "                      stream_lines: int = 100000, \n",
    "                      cutoff: float = 0.07) -> File:\n",
    "        '''doc-string\n",
    "        Todo:\n",
    "            * investigate ACT for neonates\n",
    "        '''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        # Create output filenames\n",
    "        tck: str = os.path.join(path,filename + f\".{stream_lines}.streamlines\" + \".tck\")\n",
    "        tck: File = File(tck)\n",
    "        \n",
    "        # Construct tracts\n",
    "        tckgen = Command(\"tckgen\")\n",
    "        tckgen.cmd_list.append(wm_fod.file)\n",
    "        tckgen.cmd_list.append(tck.file)\n",
    "        tckgen.cmd_list.append(\"-seed_image\")\n",
    "        tckgen.cmd_list.append(mask.file)\n",
    "        tckgen.cmd_list.append(\"-select\")\n",
    "        tckgen.cmd_list.append(f\"{stream_lines}\")\n",
    "        tckgen.cmd_list.append(\"-cutoff\")\n",
    "        tckgen.cmd_list.append(f\"{cutoff}\")\n",
    "        tckgen.run(self.log)\n",
    "        \n",
    "        return tck\n",
    "    \n",
    "    def mr_tck_sift(self,\n",
    "                   tck: File,\n",
    "                   wm_fod: Mif,\n",
    "                   term: Optional[int] = None,\n",
    "                   mask: Mif = \"\") -> File:\n",
    "        '''doc-string'''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        # Create output filenames\n",
    "        tck_filt: str = os.path.join(path,filename + f\".{term}.streamlines.filtered\" + \".tck\")\n",
    "        tck_filt: File = File(tck_filt)\n",
    "        \n",
    "        # Filter tracks\n",
    "        filt = Command(\"tcksift\")\n",
    "        filt.cmd_list.append(tck.file)\n",
    "        filt.cmd_list.append(wm_fod.file)\n",
    "        filt.cmd_list.append(tck_filt.file)\n",
    "        \n",
    "        if mask:\n",
    "            filt.cmd_list.append(\"-proc_mask\")\n",
    "            filt.cmd_list.append(mask.file)\n",
    "        \n",
    "        if term:\n",
    "            filt.cmd_list.append(\"-term_number\")\n",
    "            filt.cmd_list.append(f\"{term}\")\n",
    "        \n",
    "        filt.run(self.log)\n",
    "        \n",
    "        return tck_filt\n",
    "    \n",
    "    def compute_diff_metrics(self,\n",
    "                             dwi: Mif,\n",
    "                             mask: Optional[Mif] = None,\n",
    "                             fa: bool = True,\n",
    "                             md: bool = True,\n",
    "                             ad: bool = True,\n",
    "                             rd: bool = True,\n",
    "                             cleanup = True,\n",
    "                             force: bool = False\n",
    "                            ) -> Tuple[Mif,Mif,Mif,Mif]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        if \".gz\" in dwi.file:\n",
    "            ext = \".mif.gz\"\n",
    "        else:\n",
    "            ext = \".mif\"\n",
    "        \n",
    "        # Output file names\n",
    "        tensor: str = os.path.join(path,filename + f\".diff_tensor\" + ext)\n",
    "        md_mif: str = os.path.join(path,filename + f\".md\" + ext)\n",
    "        fa_mif: str = os.path.join(path,filename + f\".fa\" + ext)\n",
    "        ad_mif: str = os.path.join(path,filename + f\".ad\" + ext)\n",
    "        rd_mif: str = os.path.join(path,filename + f\".rd\" + ext)\n",
    "        \n",
    "        tensor: Mif = self.Mif(tensor)\n",
    "        md_mif: Mif = self.Mif(md_mif)\n",
    "        fa_mif: Mif = self.Mif(fa_mif)\n",
    "        ad_mif: Mif = self.Mif(ad_mif)\n",
    "        rd_mif: Mif = self.Mif(rd_mif)\n",
    "        \n",
    "        # Compute tensors\n",
    "        tens = Command(\"dwi2tensor\")\n",
    "        tens.cmd_list.append(dwi.file)\n",
    "        tens.cmd_list.append(tensor.file)\n",
    "        \n",
    "        if mask:\n",
    "            tens.cmd_list.append(\"-mask\")\n",
    "            tens.cmd_list.append(mask.file)\n",
    "        \n",
    "        if force:\n",
    "            tens.cmd_list.append(\"-force\")\n",
    "        \n",
    "        tens.run(self.log)\n",
    "        \n",
    "        # Compute diffusion tensor metrics\n",
    "        metric = Command(\"tensor2metric\")\n",
    "        metric.cmd_list.append(tensor.file)\n",
    "        \n",
    "        if md:\n",
    "            metric.cmd_list.append(\"-adc\")\n",
    "            metric.cmd_list.append(md_mif.file)\n",
    "        \n",
    "        if fa:\n",
    "            metric.cmd_list.append(\"-fa\")\n",
    "            metric.cmd_list.append(fa_mif.file)\n",
    "        \n",
    "        if ad:\n",
    "            metric.cmd_list.append(\"-ad\")\n",
    "            metric.cmd_list.append(ad_mif.file)\n",
    "            \n",
    "        if rd:\n",
    "            metric.cmd_list.append(\"-rd\")\n",
    "            metric.cmd_list.append(rd_mif.file)\n",
    "        \n",
    "        metric.run(self.log)\n",
    "        \n",
    "        # Clean-up\n",
    "        if cleanup:\n",
    "            os.remove(tensor.file)\n",
    "        \n",
    "        return fa_mif,md_mif,ad_mif,rd_mif\n",
    "    \n",
    "    def structural_connectome(self,\n",
    "                              tck: File,\n",
    "                              labels: File,\n",
    "                              dwi: Optional[Mif] = None,\n",
    "                              mask: Optional[Mif] = None,\n",
    "                              fa: bool = False,\n",
    "                              md: bool = False,\n",
    "                              ad: bool = False,\n",
    "                              rd: bool = False,\n",
    "                              cleanup:bool = True,\n",
    "                              force: bool = False\n",
    "                             ) -> Tuple[File,File,File,File,File]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, _ext] = self.nii_file.file_parts()\n",
    "        \n",
    "        # Create output filenames\n",
    "        connectome: str = os.path.join(path,filename + f\".structural_connectome\" + \".txt\")\n",
    "        fa_connectome: str = os.path.join(path,filename + f\".structural_connectome.fa_weighted\" + \".txt\")\n",
    "        md_connectome: str = os.path.join(path,filename + f\".structural_connectome.md_weighted\" + \".txt\")\n",
    "        ad_connectome: str = os.path.join(path,filename + f\".structural_connectome.ad_weighted\" + \".txt\")\n",
    "        rd_connectome: str = os.path.join(path,filename + f\".structural_connectome.rd_weighted\" + \".txt\")\n",
    "        tmp_metric: str = os.path.join(path,filename + f\"metric.vertex.mean.csv\")\n",
    "        \n",
    "        connectome: File = File(connectome)\n",
    "        fa_connectome: File = File(fa_connectome)\n",
    "        md_connectome: File = File(md_connectome)\n",
    "        ad_connectome: File = File(ad_connectome)\n",
    "        rd_connectome: File = File(rd_connectome)\n",
    "        tmp_metric: File = File(tmp_metric)\n",
    "            \n",
    "        if fa or md or ad or rd:\n",
    "            if dwi:\n",
    "                [fa_mif, \\\n",
    "                 md_mif, \\\n",
    "                 ad_mif, \\\n",
    "                 rd_mif] = self.compute_diff_metrics(dwi=dwi,\n",
    "                                                     mask=mask,\n",
    "                                                     fa=fa,\n",
    "                                                     md=md,\n",
    "                                                     ad=ad,\n",
    "                                                     rd=rd,\n",
    "                                                     cleanup=cleanup,\n",
    "                                                     force=force)\n",
    "            else:\n",
    "                MRtrixError(\"Input DWI mif file was not present.\")\n",
    "            \n",
    "        # Compute structural connectome\n",
    "        ctm = Command(\"tck2connectome\")\n",
    "        ctm.cmd_list.append(tck.file)\n",
    "        ctm.cmd_list.append(labels.file)\n",
    "        ctm.cmd_list.append(connectome.file)\n",
    "        if force:\n",
    "            ctm.cmd_list.append(\"-force\")\n",
    "        ctm.run(self.log)\n",
    "        del ctm\n",
    "        \n",
    "        # Construct list of metrics\n",
    "        metrics: List[Mif] = []\n",
    "        out_files: List[File] = []\n",
    "            \n",
    "        if fa:\n",
    "            metrics.append(fa_mif)\n",
    "            out_files.append(fa_connectome)\n",
    "        if md:\n",
    "            metrics.append(md_mif)\n",
    "            out_files.append(md_connectome)\n",
    "        if ad:\n",
    "            metrics.append(ad_mif)\n",
    "            out_files.append(ad_connectome)\n",
    "        if rd:\n",
    "            metrics.append(rd_mif)\n",
    "            out_files.append(rd_connectome)\n",
    "        \n",
    "        # Compute weighted structural connectome(s)\n",
    "        if fa or md or ad or rd:\n",
    "            for item in zip(metrics,out_files):\n",
    "                # Sample mean vertex value\n",
    "                tck_smp = Command(\"tcksample\")\n",
    "                tck_smp.cmd_list.append(tck.file)\n",
    "                tck_smp.cmd_list.append(item[0].file)\n",
    "                tck_smp.cmd_list.append(tmp_metric.file)\n",
    "                tck_smp.cmd_list.append(\"-stat_tck\")\n",
    "                tck_smp.cmd_list.append(\"mean\")\n",
    "                # tck_smp.cmd_list.append(\"-force\")\n",
    "                tck_smp.run(self.log)\n",
    "                del tck_smp\n",
    "\n",
    "                # Compute weighted connectome\n",
    "                ctm = Command(\"tck2connectome\")\n",
    "                ctm.cmd_list.append(tck.file)\n",
    "                ctm.cmd_list.append(labels.file)\n",
    "                ctm.cmd_list.append(item[1].file)\n",
    "                ctm.cmd_list.append(\"-scale_file\")\n",
    "                ctm.cmd_list.append(tmp_metric.file)\n",
    "                ctm.cmd_list.append(\"-stat_edge\")\n",
    "                ctm.cmd_list.append(\"mean\")\n",
    "                ctm.run(self.log)\n",
    "                del ctm\n",
    "                \n",
    "                os.remove(tmp_metric.file)\n",
    "        \n",
    "        return connectome,fa_connectome,md_connectome,ad_connectome,rd_connectome\n",
    "    \n",
    "    # write visualization functions later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWIxfm(object):\n",
    "    '''class doc-string'''\n",
    "    \n",
    "    dwi_file: NiiFile = \"\"\n",
    "    dwi_bval: File = \"\"\n",
    "    dwi_bvec: File = \"\"\n",
    "    dwi_json: File = \"\"\n",
    "    \n",
    "    template: NiiFile = \"\"\n",
    "    template_brain:NiiFile = \"\"\n",
    "    labels: NiiFile = \"\"\n",
    "    \n",
    "    log: LogFile = \"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 dwi_file: str,\n",
    "                 dwi_bval: str,\n",
    "                 dwi_bvec: str,\n",
    "                 template: str,\n",
    "                 template_brain: str,\n",
    "                 labels: str,\n",
    "                 log:str,\n",
    "                 dwi_json: str = \"\"):\n",
    "        '''doc-string'''\n",
    "        self.dwi_file: str = dwi_file\n",
    "        self.dwi_bval: str = dwi_bval\n",
    "        self.dwi_bvec: str = dwi_bvec\n",
    "        self.dwi_json: str = dwi_json\n",
    "        self.template: str = template\n",
    "        self.template_brain: str = template_brain\n",
    "        self.labels: str = labels\n",
    "        self.log: str = log\n",
    "\n",
    "        self.dwi_file: NiiFile = NiiFile(self.dwi_file)\n",
    "        self.dwi_bval: File = File(self.dwi_bval)\n",
    "        self.dwi_bvec: File = File(self.dwi_bvec)\n",
    "        self.dwi_json: File = File(self.dwi_json)\n",
    "        self.template: NiiFile = NiiFile(self.template)\n",
    "        self.template_brain: NiiFile = NiiFile(self.template_brain)\n",
    "        self.labels: NiiFile = NiiFile(self.labels)\n",
    "        self.log: LogFile = LogFile(self.log)\n",
    "            \n",
    "    def mask_dwi(self,\n",
    "                frac_int: float = 0.5\n",
    "                ) -> Tuple[NiiFile,NiiFile,NiiFile]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, ext] = self.dwi_file.file_parts()\n",
    "        \n",
    "        brain: str = os.path.join(path,filename + \"_brain\" + ext)\n",
    "        mask: str = os.path.join(path,filename + \"_brain_mask\" + ext)\n",
    "        head: str = os.path.join(path,filename + \"_head\" + ext)\n",
    "        \n",
    "        brain: NiiFile = NiiFile(brain)\n",
    "        mask: NiiFile = NiiFile(mask)\n",
    "        head: NiiFile = NiiFile(head)\n",
    "        \n",
    "        dwi = ReconMRtrix(self.dwi_file.file,\n",
    "                         self.dwi_bval.file,\n",
    "                         self.dwi_bvec.file,\n",
    "                         self.dwi_json.file,\n",
    "                         self.log)\n",
    "        \n",
    "        mif_file = dwi.nifti_to_mif()\n",
    "        \n",
    "        [mask_mif,brain_mif,head_mif] = dwi.create_mask(mif_file,frac_int)\n",
    "        \n",
    "        # Convert NIFTI to MIF\n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(mask_mif.file)\n",
    "        mr_convert.cmd_list.append(mask.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(brain_mif.file)\n",
    "        mr_convert.cmd_list.append(brain.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        mr_convert = Command(\"mrconvert\")\n",
    "        mr_convert.cmd_list.append(head_mif.file)\n",
    "        mr_convert.cmd_list.append(head.file)\n",
    "        mr_convert.run(self.log)\n",
    "        \n",
    "        # Clean-up\n",
    "        os.remove(mask_mif.file)\n",
    "        os.remove(brain_mif.file)\n",
    "        os.remove(head_mif.file)\n",
    "        \n",
    "        return mask,brain,head\n",
    "    \n",
    "    def compute_linear_xfm(self,\n",
    "                           dwi_brain: NiiFile,\n",
    "                           dof: int = 12\n",
    "                          ) -> Tuple[File,NiiFile]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, ext] = self.dwi_file.file_parts()\n",
    "        \n",
    "        xfm_mat: str = os.path.join(path,filename + f\".lin_xfm_{dof}_dof\" + \".mat\")\n",
    "        xfm_out: str = os.path.join(path,filename + f\".lin_xfm_{dof}_dof\" + ext)\n",
    "            \n",
    "        xfm_mat: File = File(xfm_mat)\n",
    "        xfm_out: NiiFile = NiiFile(xfm_out)\n",
    "        \n",
    "        if not dwi_brain.file:\n",
    "            FSLError(\"DWI file not present.\")\n",
    "        \n",
    "        lin_xfm = Command(\"flirt\")\n",
    "        lin_xfm.cmd_list.append(\"-in\")\n",
    "        lin_xfm.cmd_list.append(self.template_brain.abs_path())\n",
    "        lin_xfm.cmd_list.append(\"-ref\")\n",
    "        lin_xfm.cmd_list.append(dwi_brain.abs_path())\n",
    "        lin_xfm.cmd_list.append(\"-omat\")\n",
    "        lin_xfm.cmd_list.append(xfm_mat.file)\n",
    "        lin_xfm.cmd_list.append(\"-out\")\n",
    "        lin_xfm.cmd_list.append(xfm_out.file)\n",
    "        \n",
    "        lin_xfm.run(self.log)\n",
    "        \n",
    "        return xfm_mat,xfm_out\n",
    "    \n",
    "    def compute_non_linear_xfm(self,\n",
    "                               xfm_mat: File,\n",
    "                               dwi_head: NiiFile\n",
    "                              ) -> Tuple[NiiFile,NiiFile,NiiFile]:\n",
    "        '''doc-string'''\n",
    "        [path, filename, ext] = self.dwi_file.file_parts()\n",
    "        \n",
    "        nl_out: str = os.path.join(path,filename + f\".non-lin_xfm\" + ext)\n",
    "        nl_warp: str = os.path.join(path,filename + f\".non-lin_xfm.warp_field\" + ext)\n",
    "        nl_wpcf: str = os.path.join(path,filename + f\".non-lin_xfm.warp_field_coeff\" + ext)\n",
    "        \n",
    "        nl_out: NiiFile = NiiFile(nl_out)\n",
    "        nl_warp: NiiFile = NiiFile(nl_warp)\n",
    "        nl_wpcf: NiiFile = NiiFile(nl_wpcf)\n",
    "        \n",
    "        if not xfm_mat.file:\n",
    "            FSLError(\"Linear transformation matrix not present.\")\n",
    "        \n",
    "        if not dwi_head.file:\n",
    "            FSLError(\"DWI file not present.\")\n",
    "        \n",
    "        non_lin = Command(\"fnirt\")\n",
    "        non_lin.cmd_list.append(f\"--in={self.template.abs_path()}\")\n",
    "        non_lin.cmd_list.append(f\"--ref={dwi_head.abs_path()}\")\n",
    "        non_lin.cmd_list.append(f\"--aff={xfm_mat.file}\")\n",
    "        non_lin.cmd_list.append(f\"--iout={nl_out.file}\")\n",
    "        non_lin.cmd_list.append(f\"--fout={nl_warp.file}\")\n",
    "        non_lin.cmd_list.append(f\"--cout={nl_wpcf.file}\")\n",
    "        non_lin.run(self.log)\n",
    "        \n",
    "        return nl_out,nl_warp,nl_wpcf\n",
    "    \n",
    "    def applywarp(self,\n",
    "                  dwi_head: NiiFile,\n",
    "                  non_lin_warp: NiiFile,\n",
    "                  interp: str = \"\",\n",
    "                  rel: bool = True,\n",
    "                  premat: Optional[File] = None,\n",
    "                 ) -> NiiFile:\n",
    "        '''doc-string'''\n",
    "        [path, filename, ext] = self.dwi_file.file_parts()\n",
    "        \n",
    "        out: str = os.path.join(path,filename + f\".labels.non-linear\" + ext)\n",
    "        out: NiiFile = NiiFile(out)\n",
    "        \n",
    "        if not dwi_head.file:\n",
    "            FSLError(\"DWI file not present.\")\n",
    "        \n",
    "        if not non_lin_warp.file:\n",
    "            FSLError(\"Warp file not present.\")\n",
    "        \n",
    "        warp = Command(\"applywarp\")\n",
    "        warp.cmd_list.append(f\"--in={self.labels.abs_path()}\")\n",
    "        warp.cmd_list.append(f\"--ref={dwi_head.abs_path()}\")\n",
    "        warp.cmd_list.append(f\"--warp={non_lin_warp.abs_path()}\")\n",
    "        warp.cmd_list.append(f\"--out={out.file}\")\n",
    "        \n",
    "        if premat:\n",
    "            warp.cmd_list.append(f\"--premat={premat.abs_path()}\")\n",
    "        \n",
    "        if interp:\n",
    "            warp.cmd_list.append(f\"--interp={interp}\")\n",
    "        \n",
    "        if rel:\n",
    "            warp.cmd_list.append(\"--rel\")\n",
    "        else:\n",
    "            warp.cmd_list.append(\"--abs\")\n",
    "        \n",
    "        warp.run(self.log)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_xfm(dwi: str,\n",
    "                bval: str,\n",
    "                bvec: str,\n",
    "                template: str,\n",
    "                template_brain: str,\n",
    "                labels: str,\n",
    "                json: Optional[str] = None,\n",
    "                log: Optional[str] = \"file.log\",\n",
    "                work_dir: Optional[str] = None,\n",
    "                use_cwd: bool = False,\n",
    "                dof: int = 12,\n",
    "                frac_int: float = 0.5\n",
    "               ) -> Tuple[NiiFile,NiiFile]:\n",
    "    '''doc-string'''\n",
    "    # Create temporary working directory\n",
    "    if work_dir:\n",
    "        pass\n",
    "    else:\n",
    "        work_dir = \"work.tmp\"\n",
    "        use_cwd = True\n",
    "        \n",
    "    work_tmp: TmpDir = TmpDir(work_dir,use_cwd=use_cwd)\n",
    "    work_tmp.mk_tmp_dir()\n",
    "        \n",
    "    # Copy over the required data\n",
    "    f_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(dwi),work_tmp.tmp_dir)\n",
    "    b_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(bval),work_tmp.tmp_dir)\n",
    "    e_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(bvec),work_tmp.tmp_dir)\n",
    "\n",
    "    copy(dwi,f_tmp.file)\n",
    "    copy(bval,b_tmp.file)\n",
    "    copy(bvec,e_tmp.file)\n",
    "    \n",
    "    if json:\n",
    "        j_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(json),work_tmp.tmp_dir)\n",
    "        copy(json,j_tmp.file)\n",
    "    \n",
    "    # Create Diffusion image transformation object\n",
    "    dwi = DWIxfm(dwi_file=f_tmp.file,\n",
    "                 dwi_bval=b_tmp.file,\n",
    "                 dwi_bvec=e_tmp.file,\n",
    "                 template=template,\n",
    "                 template_brain=template_brain,\n",
    "                 labels=labels,\n",
    "                 log=log,\n",
    "                 dwi_json=j_tmp.file)\n",
    "    \n",
    "    # Perform brain extraction of B0s\n",
    "    [mask, brain, head] = dwi.mask_dwi(frac_int=frac_int)\n",
    "    \n",
    "    # Compute linear transform\n",
    "    [xfm_mat, xfm_out] = dwi.compute_linear_xfm(dwi_brain=brain,\n",
    "                                                dof=12)\n",
    "    \n",
    "    # Compute non-linear transform\n",
    "    [nl_out, nl_warp, nl_wpcf] = dwi.compute_non_linear_xfm(xfm_mat=xfm_mat,\n",
    "                                                            dwi_head=head)\n",
    "    \n",
    "    # Apply non-linear transform to atlas/template labels\n",
    "    labels_native = dwi.applywarp(dwi_head=head,\n",
    "                                  non_lin_warp=nl_warp,\n",
    "                                  interp=\"nn\",\n",
    "                                  rel=True,\n",
    "                                  premat=None)\n",
    "    return labels_native, nl_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_structural_connectome(dwi: str,\n",
    "                                 bval: str,\n",
    "                                 bvec: str,\n",
    "                                 template: str,\n",
    "                                 template_brain: str,\n",
    "                                 labels: str,\n",
    "                                 json: Optional[str] = None,\n",
    "                                 log: Optional[str] = \"file.log\",\n",
    "                                 work_dir: Optional[str] = None,\n",
    "                                 use_cwd: bool = False,\n",
    "                                 force: bool = False,\n",
    "                                 gzip: bool = False,\n",
    "                                 vox: float = 1.5,\n",
    "                                 dof: int = 12,\n",
    "                                 frac_int: float = 0.5,\n",
    "                                 stream_lines: int = 1e5,\n",
    "                                 cutoff: float = 0.07,\n",
    "                                 filter_tracts: bool = False,\n",
    "                                 term: Optional[int] = None,\n",
    "                                 fa: bool = True,\n",
    "                                 md: bool = True,\n",
    "                                 ad: bool = True,\n",
    "                                 rd: bool = True,\n",
    "                                 cleanup = True\n",
    "                                ) -> Tuple[File,File,File,File,File,NiiFile,NiiFile]:\n",
    "    '''doc-string'''\n",
    "    # Create temporary working directory\n",
    "    if work_dir:\n",
    "        pass\n",
    "    else:\n",
    "        work_dir = \"work.tmp\"\n",
    "        use_cwd = True\n",
    "        \n",
    "    work_tmp: TmpDir = TmpDir(work_dir,use_cwd=use_cwd)\n",
    "    work_tmp.mk_tmp_dir()\n",
    "        \n",
    "    # Copy over the required data\n",
    "    f_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(dwi),work_tmp.tmp_dir)\n",
    "    b_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(bval),work_tmp.tmp_dir)\n",
    "    e_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(bvec),work_tmp.tmp_dir)\n",
    "\n",
    "    copy(dwi,f_tmp.file)\n",
    "    copy(bval,b_tmp.file)\n",
    "    copy(bvec,e_tmp.file)\n",
    "    \n",
    "    if json:\n",
    "        j_tmp: TmpFile = work_tmp.TmpFile(os.path.basename(json),work_tmp.tmp_dir)\n",
    "        copy(json,j_tmp.file)\n",
    "    else:\n",
    "        j_tmp = None\n",
    "    \n",
    "    # Transform atlas labels to subject space\n",
    "    [labels_native, non_lin_out] = compute_xfm(dwi=f_tmp.file, \n",
    "                                               bval=b_tmp.file,\n",
    "                                               bvec=e_tmp.file,\n",
    "                                               template=template,\n",
    "                                               template_brain=template_brain,\n",
    "                                               labels=labels,\n",
    "                                               json=j_tmp,\n",
    "                                               log=log,\n",
    "                                               work_dir=work_dir,\n",
    "                                               use_cwd=use_cwd,\n",
    "                                               dof=dof,\n",
    "                                               frac_int=frac_int)\n",
    "    \n",
    "    # Create MRtrix difussion image processing object\n",
    "    mr_diff = ReconMRtrix(nii_file=f_tmp.file,\n",
    "                          bval=b_tmp.file,\n",
    "                          bvec=e_tmp.file,\n",
    "                          json=j_tmp.file,\n",
    "                          log=log)\n",
    "    \n",
    "    # Convert NIFTI file to MIF file\n",
    "    dwi_miff = mr_diff.nifti_to_mif(force=force,\n",
    "                                   gzip=gzip)\n",
    "    \n",
    "    # Estimate response function(s)\n",
    "    [wm_res, gm_res, csf_res] = mr_diff.estimate_response(mif=dwi_miff,\n",
    "                                                          force=force)\n",
    "    \n",
    "    # Upsample dwi and native space labels\n",
    "    up_dwi_mif = mr_diff.mr_upsample(mif=dwi_miff,\n",
    "                                     vox=vox)\n",
    "    \n",
    "    up_labels_native = mr_diff.mr_upsample(mif=labels_native,\n",
    "                                           vox=vox)\n",
    "    \n",
    "    # Perform brain extraction of B0s\n",
    "    [mask, brain, head] = mr_diff.create_mask(mif=up_mif,\n",
    "                                              frac_int=frac_int,\n",
    "                                              cleanup=True)\n",
    "    \n",
    "    # Compute single-shell 3-tissue CSD\n",
    "    [wm_fod, gm, csf] = mr_diff.ss3t_csd(mif=up_mif, \n",
    "                                         mask=mask, \n",
    "                                         wm_res=wm_res, \n",
    "                                         gm_res=gm_res, \n",
    "                                         csf_res=csf_res)\n",
    "    \n",
    "    # Perform joint bias-field correction\n",
    "    [wm_fod_norm, gm_norm, csf_norm] = mr_diff.bias_field_correction(wm_fod=wm_fod, \n",
    "                                                                     gm_tis=gm, \n",
    "                                                                     csf_tis=csf, \n",
    "                                                                     mask=mask)\n",
    "    \n",
    "    # Compute DEC and VF maps [for QC purposes]\n",
    "    [dec, vf] = mr_diff.compute_dec_map(wm_fod=wm_fod_norm, \n",
    "                                        gm_tis=gm_norm,\n",
    "                                        csf_tis=csf_norm,\n",
    "                                        mask=mask)\n",
    "    \n",
    "    # Reconstruct Fiber tracts\n",
    "    if filter_tracts:\n",
    "        tmp_tcks = mr_diff.mr_tck_global(wm_fod=wm_fod_norm,\n",
    "                                         mask=mask,\n",
    "                                         stream_lines=stream_lines,\n",
    "                                         cutoff=cutoff)\n",
    "        tcks = mr_diff.mr_tck_sift(tck=tmp_tcks,\n",
    "                                   wm_fod=wm_fod_norm,\n",
    "                                   term=term,\n",
    "                                   mask=mask)\n",
    "    else:\n",
    "        tcks = mr_diff.mr_tck_global(wm_fod=wm_fod_norm,\n",
    "                                     mask=mask,\n",
    "                                     stream_lines=stream_lines,\n",
    "                                     cutoff=cutoff)\n",
    "    \n",
    "    # Compute structural connectome\n",
    "    [connectome, \\\n",
    "     fa_connectome, \\\n",
    "     md_connectome, \\\n",
    "     ad_connectome, \\\n",
    "     rd_connectome] = mr_diff.structural_connectome(tck=tcks,\n",
    "                                                    labels=up_labels_native,\n",
    "                                                    dwi=up_dwi_mif,\n",
    "                                                    mask=mask,\n",
    "                                                    fa=fa,\n",
    "                                                    md=md,\n",
    "                                                    ad=ad,\n",
    "                                                    rd=rd,\n",
    "                                                    force=force,\n",
    "                                                    cleanup=cleanup)\n",
    "    \n",
    "    return connectome, fa_connectome, md_connectome, ad_connectome, rd_connectome, labels_native, head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"../sub-C01/ses-001/dwi/bval-b2000_run-01/sub-C01_ses-001_bval-b2000_run-01_dwi.nii.gz\"\n",
    "b = \"../sub-C01/ses-001/dwi/bval-b2000_run-01/sub-C01_ses-001_bval-b2000_run-01_dwi.bval\"\n",
    "e = \"../sub-C01/ses-001/dwi/bval-b2000_run-01/sub-C01_ses-001_bval-b2000_run-01_dwi.bvec\"\n",
    "j = \"../sub-C01/ses-001/dwi/bval-b2000_run-01/sub-C01_ses-001_bval-b2000_run-01_dwi.json\"\n",
    "log = \"sub-test.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"../UNC_AAL/infant-neo_1mm.nii\"\n",
    "labels = \"../UNC_AAL/infant-neo-aal.nii\"\n",
    "template_brain = \"../UNC_AAL/infant-neo_1mm_brain.nii\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[connectome, \\\n",
    " fa_connectome, \\\n",
    " md_connectome, \\\n",
    " ad_connectome, \\\n",
    " rd_connectome, \\\n",
    " labels_native, \\\n",
    " head] = create_structural_connectome(dwi=f,\n",
    "                                     bval=b,\n",
    "                                     bvece,\n",
    "                                     template=template,\n",
    "                                     template_brain=template_brain,\n",
    "                                     labels=labels,\n",
    "                                     json=j,\n",
    "                                     log=\"integration-test.log\",\n",
    "                                     work_dir=\"work.tmp\",\n",
    "                                     use_cwd=True,\n",
    "                                     force: bool = False,\n",
    "                                     gzip: bool = False,\n",
    "                                     vox: float = 1.5,\n",
    "                                     dof: int = 12,\n",
    "                                     frac_int: float = 0.5,\n",
    "                                     stream_lines: int = 1e5,\n",
    "                                     cutoff: float = 0.07,\n",
    "                                     filter_tracts: bool = False,\n",
    "                                     term: Optional[int] = None,\n",
    "                                     fa: bool = True,\n",
    "                                     md: bool = True,\n",
    "                                     ad: bool = True,\n",
    "                                     rd: bool = True,\n",
    "                                     cleanup = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
